{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3176,"sourceType":"datasetVersion","datasetId":1835},{"sourceId":11683,"sourceType":"datasetVersion","datasetId":8352},{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#--- Imports ---#\n\nimport numpy as np\nimport pandas as pd\nimport io\nfrom tqdm import tqdm\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer \nimport os, re, csv, math, codecs\nfrom sklearn import model_selection\nfrom sklearn import metrics\nimport torch\nimport torch.nn as nn\nimport tensorflow as tf  # we use both tensorflow and pytorch (pytorch for main part) , tensorflow for tokenizer\n\ntorch.manual_seed(1024);","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-08T10:50:08.063180Z","iopub.execute_input":"2023-11-08T10:50:08.063843Z","iopub.status.idle":"2023-11-08T10:50:25.173834Z","shell.execute_reply.started":"2023-11-08T10:50:08.063793Z","shell.execute_reply":"2023-11-08T10:50:25.172338Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#--- Constants ---#\n\nFOLDS = 5 # Define the number of folds for K-Fold cross-validation.\nMAX_LEN = 128\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 8\nEPOCHS = 5","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:50:25.176670Z","iopub.execute_input":"2023-11-08T10:50:25.177551Z","iopub.status.idle":"2023-11-08T10:50:25.183353Z","shell.execute_reply.started":"2023-11-08T10:50:25.177510Z","shell.execute_reply":"2023-11-08T10:50:25.182240Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"#--- Read data ---#\n\ndf = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:50:25.184555Z","iopub.execute_input":"2023-11-08T10:50:25.185151Z","iopub.status.idle":"2023-11-08T10:50:26.851019Z","shell.execute_reply.started":"2023-11-08T10:50:25.185082Z","shell.execute_reply":"2023-11-08T10:50:26.849791Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      One of the other reviewers has mentioned that ...  positive\n1      A wonderful little production. <br /><br />The...  positive\n2      I thought this was a wonderful way to spend ti...  positive\n3      Basically there's a family where a little boy ...  negative\n4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n...                                                  ...       ...\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#--- Convert sentiment to numerical values ---#\n\ndf.sentiment = df.sentiment.apply(lambda x: 1 if x=='positive' else 0)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:50:26.854512Z","iopub.execute_input":"2023-11-08T10:50:26.855323Z","iopub.status.idle":"2023-11-08T10:50:26.919173Z","shell.execute_reply.started":"2023-11-08T10:50:26.855276Z","shell.execute_reply":"2023-11-08T10:50:26.917965Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  review  sentiment\n0      One of the other reviewers has mentioned that ...          1\n1      A wonderful little production. <br /><br />The...          1\n2      I thought this was a wonderful way to spend ti...          1\n3      Basically there's a family where a little boy ...          0\n4      Petter Mattei's \"Love in the Time of Money\" is...          1\n...                                                  ...        ...\n49995  I thought this movie did a down right good job...          1\n49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n49997  I am a Catholic taught in parochial elementary...          0\n49998  I'm going to have to disagree with the previou...          0\n49999  No one expects the Star Trek movies to be high...          0\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#--- Cross validation ---#\n\ndf['kfold'] = -1 # Create 'kfold' column with initial value '-1'.\n                               \ndf = (df                        # Randomize rows.\n        .sample(frac=1)         # Randomly sample fraction of dataset. When `frac=1`, sample entire dataset.\n        .reset_index(drop=True) # Reset dataframe index. When `drop=True`, old index will not be added to dataframe.\n)\n\ny = df.sentiment.values # Get labels.\n\nkf = model_selection.StratifiedKFold(n_splits=FOLDS) # Divide data into `n_splits=folds` folds\n                                                     # with same class distribution (stratified).\n\nfor fold, (train_, valid_) in enumerate( # Get the fold number using enumerate.\n    kf.split(X=df, y=y) ):               # Returns generator object with 5 arrays of indices.\n    \n    df.loc[valid_, 'kfold'] = fold # Assig fold number to 'kfold' column`.\n    \ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:50:26.920996Z","iopub.execute_input":"2023-11-08T10:50:26.921427Z","iopub.status.idle":"2023-11-08T10:50:26.982928Z","shell.execute_reply.started":"2023-11-08T10:50:26.921383Z","shell.execute_reply":"2023-11-08T10:50:26.981997Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                  review  sentiment  kfold\n0      I have to admit that Tsui Hark is one of a kin...          1      0\n1      I would just like to say, that no matter how l...          1      0\n2      Oh dear, Oh dear. I started watching this not ...          0      0\n3      I was expecting a lot from Mr.Amitabh Bachan's...          0      0\n4      I originally saw this very dark comedy around ...          1      0\n...                                                  ...        ...    ...\n49995  A couple of friends and myself visited the vid...          0      4\n49996  I am at a distinct disadvantage here. I have n...          0      4\n49997  OK.... I just have 3 words - cheesy, cheesy an...          0      4\n49998  It was on at 7:30am, too close to school to se...          1      4\n49999  Why can't there be better TV movies made I was...          0      4\n\n[50000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I have to admit that Tsui Hark is one of a kin...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I would just like to say, that no matter how l...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Oh dear, Oh dear. I started watching this not ...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I was expecting a lot from Mr.Amitabh Bachan's...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I originally saw this very dark comedy around ...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>A couple of friends and myself visited the vid...</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>I am at a distinct disadvantage here. I have n...</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>OK.... I just have 3 words - cheesy, cheesy an...</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>It was on at 7:30am, too close to school to se...</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>Why can't there be better TV movies made I was...</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#--- Load FastText Embeddings ---#\n\nfasttext_embedding = {}\n\nf = codecs.open('../input/fasttext/wiki.simple.vec', encoding='utf-8')\n\nfor line in tqdm(f):\n    values = line.rstrip().rsplit(' ')\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    fasttext_embedding[word] = coefs\n    \nf.close()\n\nfasttext_embedding['hello'].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:50:26.984609Z","iopub.execute_input":"2023-11-08T10:50:26.985374Z","iopub.status.idle":"2023-11-08T10:50:46.380591Z","shell.execute_reply.started":"2023-11-08T10:50:26.985331Z","shell.execute_reply":"2023-11-08T10:50:46.379009Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"111052it [00:19, 5736.25it/s]\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(300,)"},"metadata":{}}]},{"cell_type":"code","source":"#--- Load GloVe Embedding ---#\n\nglove = pd.read_csv('../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt',\n                    sep=\" \", quoting=3, header=None, index_col=0)\n\nglove_embedding = {key: val.values for key, val in glove.T.items()}\n\nglove_embedding['hello'].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:50:46.382314Z","iopub.execute_input":"2023-11-08T10:50:46.382650Z","iopub.status.idle":"2023-11-08T10:51:14.775414Z","shell.execute_reply.started":"2023-11-08T10:50:46.382621Z","shell.execute_reply":"2023-11-08T10:51:14.774634Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(100,)"},"metadata":{}}]},{"cell_type":"code","source":"#--- Function: Create Embedding Matrix ---#\n\ndef create_embedding_matrix(word_index, embedding_dict=None, d_model=100):\n    \"\"\"\n     this function create the embedding matrix save in numpy array\n    :param word_index: a dictionary with word: index_value\n    :param embedding_dict: a dict with word embedding\n    :d_model: the dimension of word pretrained embedding, here I just set to 100, we will define again\n    :return a numpy array with embedding vectors for all known words\n    \"\"\"\n    embedding_matrix = np.zeros((len(word_index) + 1, d_model))\n    ## loop over all the words\n    for word, index in word_index.items():\n        if word in embedding_dict:\n            embedding_matrix[index] = embedding_dict[word]\n    return embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:51:14.777444Z","iopub.execute_input":"2023-11-08T10:51:14.777841Z","iopub.status.idle":"2023-11-08T10:51:14.786326Z","shell.execute_reply.started":"2023-11-08T10:51:14.777810Z","shell.execute_reply":"2023-11-08T10:51:14.784670Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#--- Class: Dataset ---#\n\nclass IMDBDataset:\n    def __init__(self, reviews, sentiments):\n        \"\"\"\n        Parameters\n        ----------\n        reviews: NumPy array\n        sentiments: NumPy array\n\n        Returns\n        -------\n        Dictionary\n            A dictionary containing X and Y tensors.\n        \"\"\"\n        self.reviews = reviews\n        self.sentiments = sentiments\n    \n    def __len__(self):\n        \"\"\"Returns length of dataset.\"\"\"\n        return len(self.reviews)\n    \n    def __getitem__(self, index):\n        \"\"\"Returns tensors of review and sentiment of given index.\"\"\"\n        review = torch.tensor(self.reviews[index,:], dtype = torch.long)\n        sentiment = torch.tensor(self.sentiments[index], dtype = torch.float)\n        \n        return {'review': review,\n                'target': sentiment}","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:51:14.787785Z","iopub.execute_input":"2023-11-08T10:51:14.788112Z","iopub.status.idle":"2023-11-08T10:51:14.801016Z","shell.execute_reply.started":"2023-11-08T10:51:14.788083Z","shell.execute_reply":"2023-11-08T10:51:14.799700Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#--- Class: LSTM Model --#\n\nclass LSTM(nn.Module):\n    def __init__(self, embedding_matrix):\n        \"\"\"\n        Given embedding_matrix: numpy array with vector for all words\n        return prediction ( in torch tensor format)\n        \"\"\"\n        super(LSTM, self).__init__()\n        # Number of words = number of rows in embedding matrix\n        num_words = embedding_matrix.shape[0]\n        # Dimension of embedding is num of columns in the matrix\n        embedding_dim = embedding_matrix.shape[1]\n        # Define an input embedding layer\n        self.embedding = nn.Embedding(\n                                      num_embeddings=num_words,\n                                      embedding_dim=embedding_dim)\n        # Embedding matrix actually is collection of parameter\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype = torch.float32))\n        # Because we use pretrained embedding (GLove, Fastext,etc) so we turn off requires_grad-meaning we do not train gradient on embedding weight\n        self.embedding.weight.requires_grad = False\n        # LSTM with hidden_size = 128\n        self.lstm = nn.LSTM(\n                            embedding_dim, \n                            128,\n                            bidirectional=True,\n                            batch_first=True,\n                             )\n        # Input(512) because we use bi-directional LSTM ==> hidden_size*2 + maxpooling **2  = 128*4 = 512, will be explained more on forward method\n        self.out = nn.Linear(512, 1)\n    def forward(self, x):\n        # pass input (tokens) through embedding layer\n        x = self.embedding(x)\n        # fit embedding to LSTM\n        hidden, _ = self.lstm(x)\n        # apply mean and max pooling on lstm output\n        avg_pool= torch.mean(hidden, 1)\n        max_pool, index_max_pool = torch.max(hidden, 1)\n        # concat avg_pool and max_pool ( so we have 256 size, also because this is bidirectional ==> 256*2 = 512)\n        out = torch.cat((avg_pool, max_pool), 1)\n        # fit out to self.out to conduct dimensionality reduction from 512 to 1\n        out = self.out(out)\n        # return output\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:51:14.803860Z","iopub.execute_input":"2023-11-08T10:51:14.805179Z","iopub.status.idle":"2023-11-08T10:51:14.818683Z","shell.execute_reply.started":"2023-11-08T10:51:14.805123Z","shell.execute_reply":"2023-11-08T10:51:14.817677Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#--- Function: Train---#\n\ndef train(data_loader, model, optimizer, device):\n    \"\"\"\n    this is model training for one epoch\n    data_loader:  this is torch dataloader, just like dataset but in torch and devide into batches\n    model : lstm\n    optimizer : torch optimizer : adam\n    device:  cuda or cpu\n    \"\"\"\n    # set model to training mode\n    model.train()\n    # go through batches of data in data loader\n    for data in data_loader:\n        reviews = data['review']\n        targets = data['target']\n        # move the data to device that we want to use\n        reviews = reviews.to(device, dtype = torch.long)\n        targets = targets.to(device, dtype = torch.float)\n        # clear the gradient\n        optimizer.zero_grad()\n        # make prediction from model\n        predictions = model(reviews)\n        # caculate the losses\n        loss = nn.BCEWithLogitsLoss()(predictions, targets.view(-1,1))\n        # backprob\n        loss.backward()\n        #single optimization step\n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:51:14.822168Z","iopub.execute_input":"2023-11-08T10:51:14.823013Z","iopub.status.idle":"2023-11-08T10:51:14.837017Z","shell.execute_reply.started":"2023-11-08T10:51:14.822953Z","shell.execute_reply":"2023-11-08T10:51:14.835718Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#--- Function: Evaluate ---#\n\ndef evaluate(data_loader, model, device):\n    final_predictions = []\n    final_targets = []\n    model.eval()\n    # turn off gradient calculation\n    with torch.no_grad():\n        for data in data_loader:\n            reviews = data['review']\n            targets = data['target']\n            reviews = reviews.to(device, dtype = torch.long)\n            targets = targets.to(device, dtype=torch.float)\n            # make prediction\n            predictions = model(reviews)\n            # move prediction and target to cpu\n            predictions = predictions.cpu().numpy().tolist()\n            targets = data['target'].cpu().numpy().tolist()\n            # add predictions to final_prediction\n            final_predictions.extend(predictions)\n            final_targets.extend(targets)\n    return final_predictions, final_targets","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:51:14.838854Z","iopub.execute_input":"2023-11-08T10:51:14.839960Z","iopub.status.idle":"2023-11-08T10:51:14.853162Z","shell.execute_reply.started":"2023-11-08T10:51:14.839921Z","shell.execute_reply":"2023-11-08T10:51:14.851684Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#--- Model Training with FastText Embedding ---#\n\ntokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(df.review.values.tolist())\n\nembedding_matrix = create_embedding_matrix(tokenizer.word_index, embedding_dict=fasttext_embedding, d_model=300)\n\n# I just run 1 fold to reduce the time. You can try more fold to get better generalization\nfor fold in range(1):\n    # STEP 2: cross validation\n    train_df = df[df.kfold != fold].reset_index(drop=True)\n    valid_df = df[df.kfold == fold].reset_index(drop=True)\n    \n    # STEP 3: pad sequence\n    xtrain = tokenizer.texts_to_sequences(train_df.review.values)\n    xtest = tokenizer.texts_to_sequences(valid_df.review.values)\n    \n    # zero padding\n    xtrain = tf.keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=MAX_LEN)\n    xtest = tf.keras.preprocessing.sequence.pad_sequences(xtest, maxlen=MAX_LEN)\n    \n    # STEP 4: initialize dataset class for training\n    train_dataset = IMDBDataset(reviews=xtrain, sentiments=train_df.sentiment.values)\n    \n    # STEP 5: Load dataset to Pytorch DataLoader\n    # after we have train_dataset, we create a torch dataloader to load train_dataset class based on specified batch_size\n    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, num_workers=2)\n    # initialize dataset class for validation\n    valid_dataset = IMDBDataset(reviews=xtest, sentiments=valid_df.sentiment.values)\n    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, num_workers=1)\n    \n    # STEP 6: Running \n    device = torch.device('cuda')\n    # feed embedding matrix to lstm\n    model_fasttext = LSTM(embedding_matrix)\n    # set model to cuda device\n    model_fasttext.to(device)\n    # initialize Adam optimizer\n    optimizer = torch.optim.Adam(model_fasttext.parameters(), lr=1e-3)\n    \n    print('training model')\n   \n    for epoch in range(EPOCHS):\n        #train one epoch\n        train(train_data_loader, model_fasttext, optimizer, device)\n        #validate\n        outputs, targets = evaluate(valid_data_loader, model_fasttext, device)\n        # threshold\n        outputs = np.array(outputs) >= 0.5\n        # calculate accuracy\n        accuracy = metrics.accuracy_score(targets, outputs)\n        print(f'FOLD:{fold}, epoch: {epoch}, accuracy_score: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:51:14.855511Z","iopub.execute_input":"2023-11-08T10:51:14.855949Z","iopub.status.idle":"2023-11-08T10:51:42.532563Z","shell.execute_reply.started":"2023-11-08T10:51:14.855911Z","shell.execute_reply":"2023-11-08T10:51:42.530424Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m model_fasttext \u001b[38;5;241m=\u001b[39m LSTM(embedding_matrix)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# set model to cuda device\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mmodel_fasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# initialize Adam optimizer\u001b[39;00m\n\u001b[1;32m     39\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model_fasttext\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"],"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error"}]},{"cell_type":"code","source":"#--- Model Training with GloVe Embedding ---#\n\ntokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(df.review.values.tolist())\n\nembedding_matrix = create_embedding_matrix(tokenizer.word_index, embedding_dict=glove_embedding, d_model=100)\n\nfor fold in range(1):\n    # STEP 2: cross validation\n    train_df = df[df.kfold != fold].reset_index(drop=True)\n    valid_df = df[df.kfold == fold].reset_index(drop=True)\n    \n    # STEP 3: pad sequence\n    xtrain = tokenizer.texts_to_sequences(train_df.review.values)\n    xtest = tokenizer.texts_to_sequences(valid_df.review.values)\n    \n    # zero padding\n    xtrain = tf.keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=MAX_LEN)\n    xtest = tf.keras.preprocessing.sequence.pad_sequences(xtest, maxlen=MAX_LEN)\n    \n    # STEP 4: initialize dataset class for training\n    train_dataset = IMDBDataset(reviews=xtrain, sentiments=train_df.sentiment.values)\n    \n    # STEP 5: Load dataset to Pytorch DataLoader\n    # after we have train_dataset, we create a torch dataloader to load train_dataset class based on specified batch_size\n    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, num_workers=2)\n    # initialize dataset class for validation\n    valid_dataset = IMDBDataset(reviews=xtest, sentiments=valid_df.sentiment.values)\n    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, num_workers=1)\n    \n    # STEP 6: Running \n    device = torch.device('cuda')\n    # feed embedding matrix to lstm\n    model_glove = LSTM(embedding_matrix)\n    # set model to cuda device\n    model_glove.to(device)\n    # initialize Adam optimizer\n    optimizer = torch.optim.Adam(model_glove.parameters(), lr=1e-3)\n    \n    print('training model')\n   \n    for epoch in range(EPOCHS):\n        #train one epoch\n        train(train_data_loader, model_glove, optimizer, device)\n        #validate\n        outputs, targets = evaluate(valid_data_loader, model_glove, device)\n        # threshold\n        outputs = np.array(outputs) >= 0.5\n        # calculate accuracy\n        accuracy = metrics.accuracy_score(targets, outputs)\n        print(f'FOLD:{fold}, epoch: {epoch}, accuracy_score: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:51:42.534217Z","iopub.status.idle":"2023-11-08T10:51:42.534691Z","shell.execute_reply.started":"2023-11-08T10:51:42.534475Z","shell.execute_reply":"2023-11-08T10:51:42.534496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--- Function: User Interaction ---#\n\ndef Interact_user_input(model):\n    '''\n    model: trained model : fasttext model or glove model\n    '''\n    model.eval()\n    \n    sentence = ''\n    while True:\n        try:\n            sentence = input('Review: ')\n            if sentence in ['q','quit']: \n                break\n            sentence = np.array([sentence])\n            sentence_token = tokenizer.texts_to_sequences(sentence)\n            sentence_token = tf.keras.preprocessing.sequence.pad_sequences(sentence_token, maxlen = MAX_LEN)\n            sentence_train = torch.tensor(sentence_token, dtype = torch.long).to(device, dtype = torch.long)\n            predict = model(sentence_train)\n            if predict.item() > 0.5:\n                print('------> Positive')\n            else:\n                print('------> Negative')\n        except KeyError:\n            print('please enter again')","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:51:42.536478Z","iopub.status.idle":"2023-11-08T10:51:42.537038Z","shell.execute_reply.started":"2023-11-08T10:51:42.536817Z","shell.execute_reply":"2023-11-08T10:51:42.536842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--- User Interaction ---#\n\nInteract_user_input(model_fasttext)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T10:51:42.538728Z","iopub.status.idle":"2023-11-08T10:51:42.539166Z","shell.execute_reply.started":"2023-11-08T10:51:42.538962Z","shell.execute_reply":"2023-11-08T10:51:42.538981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}