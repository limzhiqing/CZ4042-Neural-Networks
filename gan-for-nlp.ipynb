{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3176,"sourceType":"datasetVersion","datasetId":1835},{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#--- Imports ---#\n\nimport os\nimport random\nimport tensorflow as tf\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n# from torch.utils.data import Dataset\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import pad_sequences\n\nfrom keras.layers import Input, Embedding, Bidirectional, LSTM, \\\n                         BatchNormalization, Dropout, GlobalMaxPooling1D, Dense, dot\nfrom keras.models import Sequential, Model\nfrom keras.utils.vis_utils import plot_model\nfrom keras.optimizers import Adam\n\n\nfrom time import time\nfrom keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n\n# import torch\n# from torch import nn\n\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-06T19:27:15.793025Z","iopub.execute_input":"2023-11-06T19:27:15.793657Z","iopub.status.idle":"2023-11-06T19:27:16.415442Z","shell.execute_reply.started":"2023-11-06T19:27:15.793621Z","shell.execute_reply":"2023-11-06T19:27:16.414466Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#--- Set Random Seed ---#\n\nWORD = \"meow\"\nseed = sum(ord(char) for char in WORD)\nnp.random.seed(seed)\nrandom.seed(seed)\n# torch.manual_seed(seed)\ntf.random.set_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:16.417096Z","iopub.execute_input":"2023-11-06T19:27:16.417395Z","iopub.status.idle":"2023-11-06T19:27:16.422499Z","shell.execute_reply.started":"2023-11-06T19:27:16.417370Z","shell.execute_reply":"2023-11-06T19:27:16.421579Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#--- Constants ---#\n\nRAND_STATE = 42     # Random State.\nTRAIN_SIZE = 0.002  # Size of Training Dataset.\nTEST_SIZE  = 0.5    # Size of Test Dataset.\n\nEMBED_DIM  = 100    # Embedding Dimensions of Pretrained Embedding Model.\nLSTM_CELLS = 16     # Number of LSTM cells for LSTM layer.\nDROPOUT    = 0.5    # Dropout Rate for Dropout Layer.\nDENSE_DIM  = 16     # Dimensions of Dense Layer.\nDISC_STEPS = 1      # Number of Discriminator Steps.\n\nNOISE_DIM  = 16    # Dimension of Random Noise Vector.\nLEARN_RATE = 0.001  # Initial Learning Rate.\nLR_DECAY   = 0.95   # Learning Rate Decay.\nPATIENCE   = 10     # Early Stopping Patience.\nEPOCHS     = 10000  # Number of training epochs.\nBATCH_SIZE = 8      # Training Batch Size.","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:16.434529Z","iopub.execute_input":"2023-11-06T19:27:16.435292Z","iopub.status.idle":"2023-11-06T19:27:16.440484Z","shell.execute_reply.started":"2023-11-06T19:27:16.435260Z","shell.execute_reply":"2023-11-06T19:27:16.439755Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#--- Read Data ---#\n\ndf = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\") # Read from .csv file.\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:16.442253Z","iopub.execute_input":"2023-11-06T19:27:16.442558Z","iopub.status.idle":"2023-11-06T19:27:17.858941Z","shell.execute_reply.started":"2023-11-06T19:27:16.442534Z","shell.execute_reply":"2023-11-06T19:27:17.858000Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      One of the other reviewers has mentioned that ...  positive\n1      A wonderful little production. <br /><br />The...  positive\n2      I thought this was a wonderful way to spend ti...  positive\n3      Basically there's a family where a little boy ...  negative\n4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n...                                                  ...       ...\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#--- Label Encoding ---#\n\ndf.sentiment = df.sentiment.apply(lambda x: 1 if x=='positive' else 0) # Convert sentiment to numerical values.\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:17.860555Z","iopub.execute_input":"2023-11-06T19:27:17.860864Z","iopub.status.idle":"2023-11-06T19:27:17.908924Z","shell.execute_reply.started":"2023-11-06T19:27:17.860837Z","shell.execute_reply":"2023-11-06T19:27:17.908052Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                  review  sentiment\n0      One of the other reviewers has mentioned that ...          1\n1      A wonderful little production. <br /><br />The...          1\n2      I thought this was a wonderful way to spend ti...          1\n3      Basically there's a family where a little boy ...          0\n4      Petter Mattei's \"Love in the Time of Money\" is...          1\n...                                                  ...        ...\n49995  I thought this movie did a down right good job...          1\n49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n49997  I am a Catholic taught in parochial elementary...          0\n49998  I'm going to have to disagree with the previou...          0\n49999  No one expects the Star Trek movies to be high...          0\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#--- Split Data ---#\n\ndf_train, df_temp = train_test_split(df, test_size=(1-TRAIN_SIZE), random_state=RAND_STATE, stratify=df['sentiment'])\ndf_val,   df_test = train_test_split(df_temp, test_size=TEST_SIZE, random_state=RAND_STATE, stratify=df_temp['sentiment'])\n\ndf_train = df_train.reset_index(drop=True)\ndf_val = df_val.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)\n\n#--- Check Class Distribution ---#\n\nprint(df_train.value_counts('sentiment'))\nprint(df_val.value_counts('sentiment'))\nprint(df_test.value_counts('sentiment'))\n\n#--- Split Input and Labels ---#\n\nX_train = df_train['review']\ny_train = df_train['sentiment']\nX_val   = df_val['review']\ny_val   = df_val['sentiment']\nX_test  = df_test['review']\ny_test  = df_test['sentiment']\n\nsample_size = len(X_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:17.910090Z","iopub.execute_input":"2023-11-06T19:27:17.910467Z","iopub.status.idle":"2023-11-06T19:27:17.980880Z","shell.execute_reply.started":"2023-11-06T19:27:17.910418Z","shell.execute_reply":"2023-11-06T19:27:17.979995Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"sentiment\n0    50\n1    50\nName: count, dtype: int64\nsentiment\n0    12475\n1    12475\nName: count, dtype: int64\nsentiment\n0    12475\n1    12475\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"#--- Tokenization ---#\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train)\n\nX_train = tokenizer.texts_to_sequences(X_train)\nX_val   = tokenizer.texts_to_sequences(X_val)\nX_test  = tokenizer.texts_to_sequences(X_test)\n\nvocab_size = len(tokenizer.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:17.983055Z","iopub.execute_input":"2023-11-06T19:27:17.983337Z","iopub.status.idle":"2023-11-06T19:27:25.418067Z","shell.execute_reply.started":"2023-11-06T19:27:17.983313Z","shell.execute_reply":"2023-11-06T19:27:25.417183Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#--- Plot Sequence Lengths ---#\n\nsequence_lengths = [len(seq) for seq in X_train]\nplt.hist(sequence_lengths, bins=30)\nplt.xlabel('Sequence Length')\nplt.ylabel('Count')\nplt.show()\n\nprint(f\"Mean sequence length: {np.mean(sequence_lengths)}\")\nprint(f\"Median sequence length: {np.median(sequence_lengths)}\")\nprint(f\"Max sequence length: {max(sequence_lengths)}\")\nprint(f\"95th percentile sequence length: {np.percentile(sequence_lengths, 95)}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:25.419163Z","iopub.execute_input":"2023-11-06T19:27:25.419475Z","iopub.status.idle":"2023-11-06T19:27:25.750118Z","shell.execute_reply.started":"2023-11-06T19:27:25.419437Z","shell.execute_reply":"2023-11-06T19:27:25.749157Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Mean sequence length: 230.57\nMedian sequence length: 168.5\nMax sequence length: 1007\n95th percentile sequence length: 570.4499999999994\n","output_type":"stream"}]},{"cell_type":"code","source":"#--- Sequence Padding ---#\n\nsequence_length = int(np.percentile(sequence_lengths, 95))\n\nX_train = pad_sequences(X_train, maxlen=sequence_length)\nX_val   = pad_sequences(X_val, maxlen=sequence_length)\nX_test  = pad_sequences(X_test, maxlen=sequence_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:25.751321Z","iopub.execute_input":"2023-11-06T19:27:25.751694Z","iopub.status.idle":"2023-11-06T19:27:26.802059Z","shell.execute_reply.started":"2023-11-06T19:27:25.751668Z","shell.execute_reply":"2023-11-06T19:27:26.801063Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#--- Split Sentiment ---#\n\ntrain_positive = X_train[df_train[df_train[\"sentiment\"]==1].index]\ntrain_negative = X_train[df_train[df_train[\"sentiment\"]==0].index]","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:26.804770Z","iopub.execute_input":"2023-11-06T19:27:26.805074Z","iopub.status.idle":"2023-11-06T19:27:26.811243Z","shell.execute_reply.started":"2023-11-06T19:27:26.805048Z","shell.execute_reply":"2023-11-06T19:27:26.810306Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#--- Convert to float32 array ---#\n\nX_train = np.asarray(X_train).astype('float32')\ny_train = np.asarray(y_train).astype('float32')\nX_val   = np.asarray(X_val).astype('float32')\ny_val   = np.asarray(y_val).astype('float32')\nX_test  = np.asarray(X_test).astype('float32')\ny_test  = np.asarray(y_test).astype('float32')\ntrain_positive = np.asarray(train_positive).astype('float32')\ntrain_negative = np.asarray(train_negative).astype('float32')\n\nprint(\"X_train:\", X_train.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"X_val:\", X_val.shape)\nprint(\"y_val:\", y_val.shape)\nprint(\"X_test:\", X_test.shape)\nprint(\"y_test:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:26.812268Z","iopub.execute_input":"2023-11-06T19:27:26.812551Z","iopub.status.idle":"2023-11-06T19:27:26.864662Z","shell.execute_reply.started":"2023-11-06T19:27:26.812529Z","shell.execute_reply":"2023-11-06T19:27:26.863743Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"X_train: (100, 570)\ny_train: (100,)\nX_val: (24950, 570)\ny_val: (24950,)\nX_test: (24950, 570)\ny_test: (24950,)\n","output_type":"stream"}]},{"cell_type":"code","source":"#--- Import GloVe Embeddings ---#\n\nglove = pd.read_csv('../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\nglove_embedding = {key: val.values for key, val in glove.T.items()}\n\n#--- Create Embedding Matrix ---#\n\nembedding_matrix = np.zeros((vocab_size, EMBED_DIM))\nfor word, i in tokenizer.word_index.items():\n    if i < vocab_size:\n        if word in glove_embedding:\n            embedding_matrix[i] = glove_embedding[word]","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:26.865916Z","iopub.execute_input":"2023-11-06T19:27:26.867801Z","iopub.status.idle":"2023-11-06T19:27:48.587964Z","shell.execute_reply.started":"2023-11-06T19:27:26.867772Z","shell.execute_reply":"2023-11-06T19:27:48.587030Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#--- Callback Class: SaveWeights ---#\n\nclass SaveWeights(Callback):\n    def __init__(self):\n        super(SaveWeights, self).__init__()\n        self.weights_history = []\n\n    def on_epoch_end(self, epoch, logs=None):\n        layer_weights = self.model.layers[0].get_weights() # Get weights of first layer.\n        self.weights_history.append(layer_weights)\n        \n#--- Callback Class: TotalTime ---#\n\nclass TotalTime(Callback):\n    # Track time taken for training.\n    \n    def __init__(self):\n        super(TotalTime, self).__init__()\n        self.start_time = -1\n        self.end_time = -1\n        self.total_time = -1\n    \n    def on_train_begin(self, logs={}):\n        self.start_time = time()\n\n    def on_train_end(self, logs={}):\n        self.end_time = time()\n        self.total_time = self.end_time - self.start_time\n        \n#--- Callback Class: TimeHistory ---#\n\nclass TimeHistory(Callback):\n    # Track time taken for each epoch.\n    \n    def on_train_begin(self, logs={}):\n        self.times = []\n\n    def on_epoch_begin(self, batch, logs={}):\n        self.epoch_time_start = time()\n\n    def on_epoch_end(self, batch, logs={}):\n        self.times.append(time() - self.epoch_time_start)\n        \n#--- Callback Function for Learning Rate Scheduler ---#\n\ndef lr_schedule(epoch):\n    initial_lr = LEARN_RATE\n    learning_rate = initial_lr * (LR_DECAY ** epoch)\n    return learning_rate","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:48.589611Z","iopub.execute_input":"2023-11-06T19:27:48.589990Z","iopub.status.idle":"2023-11-06T19:27:48.600587Z","shell.execute_reply.started":"2023-11-06T19:27:48.589953Z","shell.execute_reply":"2023-11-06T19:27:48.599364Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import TextVectorization\nimport numpy as np\nimport os\nimport string\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:48.601907Z","iopub.execute_input":"2023-11-06T19:27:48.602638Z","iopub.status.idle":"2023-11-06T19:27:48.619552Z","shell.execute_reply.started":"2023-11-06T19:27:48.602609Z","shell.execute_reply":"2023-11-06T19:27:48.618501Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n    \"\"\"\n    Mask the upper half of the dot product matrix in self attention.\n    This prevents flow of information from future tokens to current token.\n    1's in the lower triangle, counting from the lower right corner.\n    \"\"\"\n    i = tf.range(n_dest)[:, None]\n    j = tf.range(n_src)\n    m = i >= j - n_src + n_dest\n    mask = tf.cast(m, dtype)\n    mask = tf.reshape(mask, [1, n_dest, n_src])\n    mult = tf.concat(\n        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n    )\n    return tf.tile(mask, mult)\n\n\nclass TransformerBlock(layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(num_heads, embed_dim)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs):\n        input_shape = tf.shape(inputs)\n        batch_size = input_shape[0]\n        seq_len = input_shape[1]\n        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n        attention_output = self.dropout1(attention_output)\n        out1 = self.layernorm1(inputs + attention_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:48.620622Z","iopub.execute_input":"2023-11-06T19:27:48.620902Z","iopub.status.idle":"2023-11-06T19:27:48.633375Z","shell.execute_reply.started":"2023-11-06T19:27:48.620878Z","shell.execute_reply":"2023-11-06T19:27:48.632513Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class TokenAndPositionEmbedding(layers.Layer):\n    def __init__(self, maxlen, vocab_size, embed_dim):\n        super().__init__()\n        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        x = self.token_emb(x)\n        return x + positions","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:27:48.634441Z","iopub.execute_input":"2023-11-06T19:27:48.634737Z","iopub.status.idle":"2023-11-06T19:27:48.651267Z","shell.execute_reply.started":"2023-11-06T19:27:48.634713Z","shell.execute_reply":"2023-11-06T19:27:48.650281Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"vocab_size = vocab_size  # Only consider the top 20k words\nmaxlen = sequence_length  # Max sequence size\nembed_dim = EMBED_DIM  # Embedding size for each token\nnum_heads = 2  # Number of attention heads\nfeed_forward_dim = 256  # Hidden layer size in feed forward network inside transformer\n\n\ndef create_model():\n    inputs = layers.Input(shape=(maxlen,), dtype=tf.int32)\n    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n    x = embedding_layer(inputs)\n    transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n    x = transformer_block(x)\n    outputs = layers.Dense(vocab_size)(x)\n    model = keras.Model(inputs=inputs, outputs=[outputs, x])\n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    model.compile(\n        \"adam\", loss=[loss_fn, None],\n    )  # No loss and optimization based on word embeddings from transformer block\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:43:23.761127Z","iopub.execute_input":"2023-11-06T19:43:23.761514Z","iopub.status.idle":"2023-11-06T19:43:23.769985Z","shell.execute_reply.started":"2023-11-06T19:43:23.761483Z","shell.execute_reply":"2023-11-06T19:43:23.768815Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"text_ds = df_train['review']\n\ndef custom_standardization(input_string):\n    \"\"\" Remove html line-break tags and handle punctuation \"\"\"\n    lowercased = tf.strings.lower(input_string)\n    stripped_html = tf.strings.regex_replace(lowercased, \"<br />\", \" \")\n    return tf.strings.regex_replace(stripped_html, f\"([{string.punctuation}])\", r\" \\1\")\n\n\n# Create a vectorization layer and adapt it to the text\nvectorize_layer = TextVectorization(\n    standardize=custom_standardization,\n    max_tokens=vocab_size - 1,\n    output_mode=\"int\",\n    output_sequence_length=maxlen + 1,\n)\nvectorize_layer.adapt(text_ds)\nvocab = vectorize_layer.get_vocabulary()  # To get words back from token indices\n\n\ndef prepare_lm_inputs_labels(text):\n    \"\"\"\n    Shift word sequences by 1 position so that the target for position (i) is\n    word at position (i+1). The model will use all words up till position (i)\n    to predict the next word.\n    \"\"\"\n    text = tf.expand_dims(text, -1)\n    tokenized_sentences = vectorize_layer(text)\n    x = tokenized_sentences[:, :-1]\n    y = tokenized_sentences[:, 1:]\n    return x, y\n\n\ntext_ds = text_ds.map(prepare_lm_inputs_labels)\n# text_ds = text_ds.prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T20:12:45.713838Z","iopub.execute_input":"2023-11-06T20:12:45.715076Z","iopub.status.idle":"2023-11-06T20:12:46.629257Z","shell.execute_reply.started":"2023-11-06T20:12:45.715033Z","shell.execute_reply":"2023-11-06T20:12:46.628495Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"class TextGenerator(keras.callbacks.Callback):\n    \"\"\"A callback to generate text from a trained model.\n    1. Feed some starting prompt to the model\n    2. Predict probabilities for the next token\n    3. Sample the next token and add it to the next input\n\n    Arguments:\n        max_tokens: Integer, the number of tokens to be generated after prompt.\n        start_tokens: List of integers, the token indices for the starting prompt.\n        index_to_word: List of strings, obtained from the TextVectorization layer.\n        top_k: Integer, sample from the `top_k` token predictions.\n        print_every: Integer, print after this many epochs.\n    \"\"\"\n\n    def __init__(\n        self, max_tokens, start_tokens, index_to_word, top_k=10, print_every=1\n    ):\n        self.max_tokens = max_tokens\n        self.start_tokens = start_tokens\n        self.index_to_word = index_to_word\n        self.print_every = print_every\n        self.k = top_k\n\n    def sample_from(self, logits):\n        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n        indices = np.asarray(indices).astype(\"int32\")\n        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n        preds = np.asarray(preds).astype(\"float32\")\n        return np.random.choice(indices, p=preds)\n\n    def detokenize(self, number):\n        return self.index_to_word[number]\n\n    def on_epoch_end(self, epoch, logs=None):\n        start_tokens = [_ for _ in self.start_tokens]\n        if (epoch + 1) % self.print_every != 0:\n            return\n        num_tokens_generated = 0\n        tokens_generated = []\n        while num_tokens_generated <= self.max_tokens:\n            pad_len = maxlen - len(start_tokens)\n            sample_index = len(start_tokens) - 1\n            if pad_len < 0:\n                x = start_tokens[:maxlen]\n                sample_index = maxlen - 1\n            elif pad_len > 0:\n                x = start_tokens + [0] * pad_len\n            else:\n                x = start_tokens\n            x = np.array([x])\n            y, _ = self.model.predict(x)\n            sample_token = self.sample_from(y[0][sample_index])\n            tokens_generated.append(sample_token)\n            start_tokens.append(sample_token)\n            num_tokens_generated = len(tokens_generated)\n        txt = \" \".join(\n            [self.detokenize(_) for _ in self.start_tokens + tokens_generated]\n        )\n        print(f\"generated text:\\n{txt}\\n\")\n\n\n# Tokenize starting prompt\nword_to_index = {}\nfor index, word in enumerate(vocab):\n    word_to_index[word] = index\n\nstart_prompt = \"this movie is\"\nstart_tokens = [word_to_index.get(_, 1) for _ in start_prompt.split()]\nnum_tokens_generated = 40\ntext_gen_callback = TextGenerator(num_tokens_generated, start_tokens, vocab)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T20:12:51.186945Z","iopub.execute_input":"2023-11-06T20:12:51.187310Z","iopub.status.idle":"2023-11-06T20:12:51.203626Z","shell.execute_reply.started":"2023-11-06T20:12:51.187279Z","shell.execute_reply":"2023-11-06T20:12:51.202633Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"model = create_model()\n\nmodel.fit(text_ds, verbose=2, epochs=25, callbacks=[text_gen_callback])","metadata":{"execution":{"iopub.status.busy":"2023-11-06T20:13:06.814421Z","iopub.execute_input":"2023-11-06T20:13:06.814790Z","iopub.status.idle":"2023-11-06T20:13:07.086077Z","shell.execute_reply.started":"2023-11-06T20:13:06.814762Z","shell.execute_reply":"2023-11-06T20:13:07.084892Z"},"trusted":true},"execution_count":90,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[90], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtext_gen_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type tuple)."],"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type tuple).","output_type":"error"}]},{"cell_type":"code","source":"type(text_ds)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T20:13:20.383180Z","iopub.execute_input":"2023-11-06T20:13:20.383561Z","iopub.status.idle":"2023-11-06T20:13:20.389597Z","shell.execute_reply.started":"2023-11-06T20:13:20.383531Z","shell.execute_reply":"2023-11-06T20:13:20.388497Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"pandas.core.series.Series"},"metadata":{}}]}]}